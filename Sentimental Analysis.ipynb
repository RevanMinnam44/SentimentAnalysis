{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c28b56ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/revan/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/revan/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('vader_lexicon')\n",
    "#from textblob import TextBlob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import subjectivity\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk import tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "443898bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment analysis not done: 1077\n",
      "Sentiment analysis not done: 2786\n",
      "Sentiment analysis not done: 7483\n",
      "Sentiment analysis not done: 7827\n",
      "Sentiment analysis not done: 8362\n",
      "Sentiment analysis not done: 11415\n",
      "Sentiment analysis not done: 11745\n",
      "Sentiment analysis not done: 13838\n",
      "Sentiment analysis not done: 14131\n",
      "Sentiment analysis not done: 16185\n",
      "Sentiment analysis not done: 18191\n",
      "Sentiment analysis not done: 19098\n",
      "Sentiment analysis not done: 19986\n",
      "Sentiment analysis not done: 21122\n",
      "Sentiment analysis not done: 21720\n",
      "Sentiment analysis not done: 22215\n",
      "Sentiment analysis not done: 25043\n",
      "Sentiment analysis not done: 25446\n",
      "Sentiment analysis not done: 26939\n",
      "Sentiment analysis not done: 27128\n",
      "Sentiment analysis not done: 28326\n",
      "Sentiment analysis not done: 31537\n",
      "Sentiment analysis not done: 32174\n",
      "Sentiment analysis not done: 32398\n",
      "Sentiment analysis not done: 35209\n",
      "Sentiment analysis not done: 36419\n",
      "Sentiment analysis not done: 38638\n",
      "Sentiment analysis not done: 39919\n",
      "Sentiment analysis not done: 40035\n",
      "Sentiment analysis not done: 41575\n",
      "Sentiment analysis not done: 41701\n",
      "Sentiment analysis not done: 41931\n",
      "Sentiment analysis not done: 43695\n",
      "Sentiment analysis not done: 44322\n",
      "Sentiment analysis not done: 46196\n",
      "Sentiment analysis not done: 46858\n",
      "Sentiment analysis not done: 50861\n",
      "Sentiment analysis not done: 50940\n",
      "Sentiment analysis not done: 51354\n",
      "Sentiment analysis not done: 51789\n",
      "Sentiment analysis not done: 52108\n",
      "Sentiment analysis not done: 53042\n",
      "Sentiment analysis not done: 53431\n",
      "Sentiment analysis not done: 53443\n",
      "Sentiment analysis not done: 54203\n",
      "Sentiment analysis not done: 54204\n",
      "Sentiment analysis not done: 57785\n",
      "Sentiment analysis not done: 62791\n",
      "Sentiment analysis not done: 63795\n",
      "Sentiment analysis not done: 64225\n",
      "Sentiment analysis not done: 65216\n",
      "Sentiment analysis not done: 65876\n",
      "Sentiment analysis not done: 68070\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>comments</th>\n",
       "      <th>negativity</th>\n",
       "      <th>neutrality</th>\n",
       "      <th>positivity</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1178162</td>\n",
       "      <td>4724140</td>\n",
       "      <td>2013-05-21</td>\n",
       "      <td>4298113</td>\n",
       "      <td>Olivier</td>\n",
       "      <td>My stay at islam's place was really cool! Good...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.9626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1178162</td>\n",
       "      <td>4869189</td>\n",
       "      <td>2013-05-29</td>\n",
       "      <td>6452964</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>Great location for both airport and city - gre...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.9061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1178162</td>\n",
       "      <td>5003196</td>\n",
       "      <td>2013-06-06</td>\n",
       "      <td>6449554</td>\n",
       "      <td>Sebastian</td>\n",
       "      <td>We really enjoyed our stay at Islams house. Fr...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.9663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1178162</td>\n",
       "      <td>5150351</td>\n",
       "      <td>2013-06-15</td>\n",
       "      <td>2215611</td>\n",
       "      <td>Marine</td>\n",
       "      <td>The room was nice and clean and so were the co...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.9267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1178162</td>\n",
       "      <td>5171140</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>6848427</td>\n",
       "      <td>Andrew</td>\n",
       "      <td>Great location. Just 5 mins walk from the Airp...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.637</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.8658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68270</th>\n",
       "      <td>7462268</td>\n",
       "      <td>80537457</td>\n",
       "      <td>2016-06-18</td>\n",
       "      <td>22034145</td>\n",
       "      <td>Antonio</td>\n",
       "      <td>Joe y su mujer son encantadores. La habitación...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68271</th>\n",
       "      <td>7462268</td>\n",
       "      <td>83640094</td>\n",
       "      <td>2016-07-03</td>\n",
       "      <td>40052513</td>\n",
       "      <td>Steve</td>\n",
       "      <td>Joe was on his way to Jamaica to be married! o...</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.9504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68272</th>\n",
       "      <td>7462268</td>\n",
       "      <td>85797088</td>\n",
       "      <td>2016-07-13</td>\n",
       "      <td>77129134</td>\n",
       "      <td>Nick</td>\n",
       "      <td>The room was very clean as were the bathrooms ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.9693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68273</th>\n",
       "      <td>7462268</td>\n",
       "      <td>97264637</td>\n",
       "      <td>2016-08-26</td>\n",
       "      <td>15799803</td>\n",
       "      <td>Vid</td>\n",
       "      <td>Staying in Lower Allston at Joe and Nancy's pl...</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.9957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68274</th>\n",
       "      <td>7462268</td>\n",
       "      <td>98550693</td>\n",
       "      <td>2016-08-31</td>\n",
       "      <td>90128094</td>\n",
       "      <td>Arianna</td>\n",
       "      <td>The room itself and the aprtment were very cle...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.7564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68275 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       listing_id        id        date  reviewer_id reviewer_name  \\\n",
       "0         1178162   4724140  2013-05-21      4298113       Olivier   \n",
       "1         1178162   4869189  2013-05-29      6452964     Charlotte   \n",
       "2         1178162   5003196  2013-06-06      6449554     Sebastian   \n",
       "3         1178162   5150351  2013-06-15      2215611        Marine   \n",
       "4         1178162   5171140  2013-06-16      6848427        Andrew   \n",
       "...           ...       ...         ...          ...           ...   \n",
       "68270     7462268  80537457  2016-06-18     22034145       Antonio   \n",
       "68271     7462268  83640094  2016-07-03     40052513         Steve   \n",
       "68272     7462268  85797088  2016-07-13     77129134          Nick   \n",
       "68273     7462268  97264637  2016-08-26     15799803           Vid   \n",
       "68274     7462268  98550693  2016-08-31     90128094       Arianna   \n",
       "\n",
       "                                                comments negativity  \\\n",
       "0      My stay at islam's place was really cool! Good...        0.0   \n",
       "1      Great location for both airport and city - gre...        0.0   \n",
       "2      We really enjoyed our stay at Islams house. Fr...        0.0   \n",
       "3      The room was nice and clean and so were the co...        0.0   \n",
       "4      Great location. Just 5 mins walk from the Airp...        0.0   \n",
       "...                                                  ...        ...   \n",
       "68270  Joe y su mujer son encantadores. La habitación...        0.0   \n",
       "68271  Joe was on his way to Jamaica to be married! o...      0.014   \n",
       "68272  The room was very clean as were the bathrooms ...        0.0   \n",
       "68273  Staying in Lower Allston at Joe and Nancy's pl...      0.014   \n",
       "68274  The room itself and the aprtment were very cle...        0.0   \n",
       "\n",
       "      neutrality positivity compound  \n",
       "0          0.648      0.352   0.9626  \n",
       "1          0.639      0.361   0.9061  \n",
       "2          0.767      0.233   0.9663  \n",
       "3          0.673      0.327   0.9267  \n",
       "4          0.637      0.363   0.8658  \n",
       "...          ...        ...      ...  \n",
       "68270      0.946      0.054     0.34  \n",
       "68271      0.822      0.164   0.9504  \n",
       "68272      0.784      0.216   0.9693  \n",
       "68273      0.759      0.226   0.9957  \n",
       "68274      0.755      0.245   0.7564  \n",
       "\n",
       "[68275 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def SentimentalAnalysis(df, text_column):\n",
    "    sentiment_analysis_columns = ['negativity', 'neutrality', 'positivity', 'compound']\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    expanded_text_dataset = []\n",
    "    column_names = list(df.columns.values)\n",
    "    all_columns = column_names + sentiment_analysis_columns\n",
    "    text_segment_list = list(df[text_column])\n",
    "    for j in range(len(text_segment_list)):\n",
    "        row_info = list(df.iloc[j])\n",
    "        text = text_segment_list[j]\n",
    "        ##Sentiment analysis\n",
    "        try:\n",
    "            ss = sid.polarity_scores(text)\n",
    "            negativity = ss['neg']\n",
    "            neutrality = ss['neu']\n",
    "            positivity = ss['pos']\n",
    "            compound = ss['compound']\n",
    "            temp_data = row_info + [negativity, neutrality, positivity, compound]\n",
    "            expanded_text_dataset.append(temp_data)\n",
    "        except:\n",
    "            print('Sentiment analysis not done: ' + str(j))\n",
    "            temp_data = row_info + ['NA', 'NA', 'NA', 'NA']\n",
    "            expanded_text_dataset.append(temp_data)\n",
    "    ##Storing the results in a dataset\n",
    "    sentiment_dataset_df = pd.DataFrame(expanded_text_dataset, columns = all_columns)\n",
    "    #sentiment_dataset_df.to_csv('%s_sentiment_analysis.csv' %file_name)\n",
    "    return sentiment_dataset_df\n",
    "\n",
    "reviews_df = pd.read_csv(\"/Users/revan/Downloads/reviews.csv\")\n",
    "\n",
    "SentimentalAnalysis(reviews_df, 'comments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5459fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SentimentalAnalysis_v2(df, text_column):\n",
    "    sentiment_analysis_columns = ['positivity_simple', 'negativity_simple']\n",
    "    positive_words = pd.read_csv(\"/Users/revan/Downloads/positive_words.csv\", header=None, names=['Words'])\n",
    "    negative_words = pd.read_csv(\"/Users/revan/Downloads/negative_words.csv\", encoding='ISO-8859-1', header=None, names=['Words'])    \n",
    "    positive_set = set(positive_words['Words'])\n",
    "    negative_set = set(negative_words['Words'])\n",
    "    expanded_text_dataset = []\n",
    "    column_names = list(df.columns.values)\n",
    "    all_columns = column_names + sentiment_analysis_columns\n",
    "    text_segment_list = list(df[text_column])\n",
    "    for j in range(len(text_segment_list)):\n",
    "        row_info = list(df.iloc[j])\n",
    "        text = text_segment_list[j]\n",
    "        words = str(text).split()                          \n",
    "        ##Sentiment analysis\n",
    "        try:            \n",
    "            pos = [word for word in words if word in positive_set]\n",
    "            neg = [word for word in words if word in negative_set]\n",
    "            positive_simple = len(pos) / len(words)\n",
    "            negative_simple = len(neg) / len(words)\n",
    "            temp_data = row_info + [positive_simple, negative_simple]\n",
    "            expanded_text_dataset.append(temp_data)\n",
    "        except:\n",
    "            print('Sentiment analysis not done: ' + str(j))\n",
    "            temp_data = row_info + [None, None]\n",
    "            expanded_text_dataset.append(temp_data)\n",
    "    ##Storing the results in a dataset\n",
    "    sentiment_dataset_df = pd.DataFrame(expanded_text_dataset, columns = all_columns)\n",
    "    #sentiment_dataset_df.to_csv('%s_sentiment_analysis.csv' %file_name)\n",
    "    return sentiment_dataset_df\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4e58637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment analysis not done: 20327\n",
      "       listing_id        id        date  reviewer_id reviewer_name  \\\n",
      "0         1178162   4724140  2013-05-21      4298113       Olivier   \n",
      "1         1178162   4869189  2013-05-29      6452964     Charlotte   \n",
      "2         1178162   5003196  2013-06-06      6449554     Sebastian   \n",
      "3         1178162   5150351  2013-06-15      2215611        Marine   \n",
      "4         1178162   5171140  2013-06-16      6848427        Andrew   \n",
      "...           ...       ...         ...          ...           ...   \n",
      "68270     7462268  80537457  2016-06-18     22034145       Antonio   \n",
      "68271     7462268  83640094  2016-07-03     40052513         Steve   \n",
      "68272     7462268  85797088  2016-07-13     77129134          Nick   \n",
      "68273     7462268  97264637  2016-08-26     15799803           Vid   \n",
      "68274     7462268  98550693  2016-08-31     90128094       Arianna   \n",
      "\n",
      "                                                comments  positivity_simple  \\\n",
      "0      My stay at islam's place was really cool! Good...           0.040816   \n",
      "1      Great location for both airport and city - gre...           0.083333   \n",
      "2      We really enjoyed our stay at Islams house. Fr...           0.034884   \n",
      "3      The room was nice and clean and so were the co...           0.111111   \n",
      "4      Great location. Just 5 mins walk from the Airp...           0.000000   \n",
      "...                                                  ...                ...   \n",
      "68270  Joe y su mujer son encantadores. La habitación...           0.000000   \n",
      "68271  Joe was on his way to Jamaica to be married! o...           0.015504   \n",
      "68272  The room was very clean as were the bathrooms ...           0.054348   \n",
      "68273  Staying in Lower Allston at Joe and Nancy's pl...           0.064748   \n",
      "68274  The room itself and the aprtment were very cle...           0.000000   \n",
      "\n",
      "       negativity_simple  \n",
      "0               0.000000  \n",
      "1               0.000000  \n",
      "2               0.023256  \n",
      "3               0.000000  \n",
      "4               0.000000  \n",
      "...                  ...  \n",
      "68270           0.000000  \n",
      "68271           0.007752  \n",
      "68272           0.000000  \n",
      "68273           0.003597  \n",
      "68274           0.000000  \n",
      "\n",
      "[68275 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(SentimentalAnalysis_v2(reviews_df, 'comments'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "407dc7bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abounds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abundance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abundant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Words\n",
       "0         a+\n",
       "1     abound\n",
       "2    abounds\n",
       "3  abundance\n",
       "4   abundant"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_words = pd.read_csv(\"/Users/revan/Downloads/positive_words.csv\", header=None, names=['Words'])\n",
    "positive_words.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91aab3ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
